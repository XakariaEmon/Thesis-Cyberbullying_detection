{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4684e670-7056-4fc5-9e74-109e4d4eb2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46ce800-d2fb-4365-8732-2a7b99c5a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e173163f-7483-4c8f-a16d-86fc37aa2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping keras as it is not installed.\n",
      "WARNING: Skipping keras-nightly as it is not installed.\n",
      "WARNING: Skipping keras-preprocessing as it is not installed.\n",
      "WARNING: Skipping tf-keras as it is not installed.\n",
      "WARNING: Skipping tensorflow as it is not installed.\n",
      "WARNING: Skipping tensorflow-gpu as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall keras keras-nightly keras-preprocessing tf-keras tensorflow tensorflow-gpu -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be986f7-217f-40f5-b702-e738c7ec0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in g:\\python\\python310\\site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in g:\\python\\python310\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in g:\\python\\python310\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in g:\\python\\python310\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\python\\python310\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\python\\python310\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\python\\python310\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in g:\\python\\python310\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in g:\\python\\python310\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in g:\\python\\python310\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\python\\python310\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in g:\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in g:\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in g:\\python\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in g:\\python\\python310\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in g:\\python\\python310\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in g:\\python\\python310\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in g:\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\python\\python310\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\python\\python310\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\python\\python310\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\python\\python310\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\python\\python310\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55e61dd-2017-46ca-95b8-b829d21817b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d0dc64-d079-4417-9695-26cfcd3d4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d6123c-aa9b-47d0-bce1-62d17c56cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'preprocessed_english_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0aa04cd-3e34-434c-8e99-0fbf4bea2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ac1f32-d784-4551-bced-dc0e46596cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    in other words katandandre, your food was crap...\n",
      "1    why is aussietv so white? mkr theblock imacele...\n",
      "2         a classy whore? or more red velvet cupcakes?\n",
      "3    meh. p  thanks for the heads up, but not too c...\n",
      "4    this is an isis account pretending to be a kur...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head()['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21db42db-fd7a-4ef5-9140-a3f1cdc2520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "classes = df['label'].unique()\n",
    "class_to_id = {cls: idx for idx, cls in enumerate(classes)}\n",
    "id_to_class = {idx: cls for cls, idx in class_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599ac839-7e56-4f18-a128-3af1dbeb0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37946538-c0d6-41bf-862f-a63fa98cedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map class labels to IDs\n",
    "df['label'] = df['label'].map(class_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e61c5058-bad8-41a0-a534-e5b97e329db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       cleaned_text\n",
      "0      0  in other words katandandre, your food was crap...\n",
      "1      0  why is aussietv so white? mkr theblock imacele...\n",
      "2      0       a classy whore? or more red velvet cupcakes?\n",
      "3      0  meh. p  thanks for the heads up, but not too c...\n",
      "4      0  this is an isis account pretending to be a kur...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043a104d-c0e5-4c08-919d-ec61d15194a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['not bully' 'religious' 'others' 'sexual']\n"
     ]
    }
   ],
   "source": [
    "# Print unique classes\n",
    "print(\"Unique Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f601b6ea-50e3-44c5-b6aa-647ed40a1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to ID Mapping: {'not bully': 0, 'religious': 1, 'others': 2, 'sexual': 3}\n"
     ]
    }
   ],
   "source": [
    "# Print the mapping from class labels to IDs\n",
    "print(\"Class to ID Mapping:\", class_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7380b108-3ec1-44f4-9924-79c7258e5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Class Mapping: {0: 'not bully', 1: 'religious', 2: 'others', 3: 'sexual'}\n"
     ]
    }
   ],
   "source": [
    "# Print the mapping from IDs back to class labels\n",
    "print(\"ID to Class Mapping:\", id_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be60815f-66da-44a8-845b-a8955964d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['cleaned_text'].values, df['label'].values, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f90f19-bb20-40db-aab4-87f1eb8656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61886f3f-a8e7-406b-b33f-ca6eff3d46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "def tokenize_function(texts):\n",
    "    # Ensure all elements are strings\n",
    "    texts = [str(text) for text in texts]  # Convert each element to string explicitly\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36a4060d-c991-4916-9b07-0460175bc1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22597"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8108594f-a17a-4384-89bb-492c592e7a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: rt    also the awesome  counted the  of women he follows amp wrote about it here\n",
      "Tokenized Text: [CLS] rt also the awesome counted the of women he follows amp wrote about it here [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Example: Get tokenized text for the first row of train_texts\n",
    "row_index = 0  # Index of the row you want to examine\n",
    "input_ids = train_encodings['input_ids'][row_index]  # Get the token IDs for the row\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "tokenized_text = tokenizer.decode(input_ids)\n",
    "\n",
    "# Print the tokenized text\n",
    "print(f\"Original Text: {train_texts[row_index]}\")\n",
    "print(f\"Tokenized Text: {tokenized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fae43655-587a-4021-b9f2-4b6cef82d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and being used: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defd7b35-ef0a-4bb9-a586-40b804421985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset class\n",
    "class CyberbullyingDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d3819a2-a51e-4a9d-8cd5-919a3dc7c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CyberbullyingDataset(train_encodings, train_labels)\n",
    "test_dataset = CyberbullyingDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3045fbfd-651c-4627-a593-38aa9d9d8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display a few samples from train_dataset\n",
    "# print(\"Sample Data from train_dataset:\")\n",
    "# for i in range(5):  # Display first 5 samples\n",
    "#     print(train_dataset[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cc44f10-b354-48c4-8a08-29508acea243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(classes))\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.3\n",
    "model.config.attention_probs_dropout_prob = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c5ca739-0c28-48ce-9d43-89a8ca369355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f8deb2-5cc4-484b-bdfb-198a5394b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1453adf7-91cd-4f79-891f-fc2e990fe506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "066bc3ba-89df-4d00-a32a-c598047bc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fab3d1c-a78c-4d83-ac4f-d7904b2e62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate scheduler\n",
    "num_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",  # Options: 'linear', 'cosine', 'constant', etc.\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c085e726-9379-4295-b238-89cc83315235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./resultsBERT0/T\",  # Directory to save model checkpoints and logs\n",
    "    num_train_epochs=15,  # Number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=16,  # Batch size for evaluation\n",
    "    warmup_steps=500,  # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.05,  # Weight decay (L2 regularization)\n",
    "    logging_dir=\"./logs\",  # Directory for storing logs\n",
    "    logging_steps=200,  # Log metrics every 200 steps\n",
    "    eval_strategy=\"epoch\",  # Evaluate the model at the end of every epoch\n",
    "    save_strategy=\"epoch\",  # Save model at the end of every epoch\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, lr_scheduler)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91b60079-bd59-428e-b099-2a2b6cdf96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "\n",
    "class BertWithExtraDropout(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.num_labels = config.num_labels  # Fix: assign num_labels here\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        if loss is not None:\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "        \n",
    "\n",
    "from transformers import BertConfig\n",
    "\n",
    "num_labels = len(classes)  # your number of classes\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "\n",
    "model = BertWithExtraDropout(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28702d86-16c8-4e69-b363-6fec8de603eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7909' max='21195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7909/21195 22:47 < 38:17, 5.78 it/s, Epoch 5.60/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.427900</td>\n",
       "      <td>1.407943</td>\n",
       "      <td>0.244779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.416600</td>\n",
       "      <td>1.407943</td>\n",
       "      <td>0.244779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>1.407943</td>\n",
       "      <td>0.244779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.420400</td>\n",
       "      <td>1.407943</td>\n",
       "      <td>0.244779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.423500</td>\n",
       "      <td>1.407943</td>\n",
       "      <td>0.244779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Python\\Python310\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Python\\Python310\\site-packages\\transformers\\trainer.py:2565\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m   2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2566\u001b[0m ):\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2569\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc360d-9afb-4f04-8fa0-d10ebc987aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fb45d-67d8-4e72-8922-c03f835e681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Get predicted labels\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b57d03-394e-4117-a418-a93f289176ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe029e-008b-43e1-af69-49703d03eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Get model predictions\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert logits to predicted labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(labels, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee327d-0c0e-43a0-a4eb-8e52272ffbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = trainer.evaluate(train_dataset)\n",
    "print(\"Training Set Metrics:\", train_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27abdc-acde-478e-9418-75350a3bc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Define the same model architecture\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "\n",
    "# Load the saved weights\n",
    "bert_model.load_state_dict(torch.load(\"bert_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "bert_model.eval()\n",
    "\n",
    "print(\"BERT model loaded successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "class CyberbullyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "        \n",
    "bert_test_dataset = torch.load(\"bert_test_dataset.pth\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dataset, batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "\n",
    "bert_accuracy, predictions, true_labels = evaluate_model(bert_model, bert_test_dataset)\n",
    "\n",
    "print(f\"BERT Model Accuracy: {bert_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c1985-c55c-4dbb-9d63-7dedb12fb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class_names = ['not bully', 'religious', 'others', 'sexual']\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix - BERT Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80555c-fba0-4944-b0a1-a63712c9b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921ead5-d8b6-4aa4-914a-4524356e4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = cohen_kappa_score(true_labels, predictions)\n",
    "print(f\"\\nCohen's Kappa Score: {kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee001b-87c5-4880-b740-cb0c7815bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logits(model, test_dataset, batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating (for ROC-AUC)\"):\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "\n",
    "probs, y_true = evaluate_logits(bert_model, bert_test_dataset)\n",
    "y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3])\n",
    "roc_auc = roc_auc_score(y_true_bin, probs, average='macro')\n",
    "print(f\"\\nMacro ROC-AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7af145-caba-4951-946f-fa19494f3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Your class names\n",
    "class_names = ['not bully', 'religious', 'others', 'sexual']\n",
    "\n",
    "# Binarize true labels\n",
    "y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3])\n",
    "n_classes = y_true_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Create single ROC plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]*100:.2f}%)\")\n",
    "\n",
    "# Plot the diagonal reference line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 50%)')\n",
    "\n",
    "# Formatting\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curves - BERT Model')\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bert_roc_curve.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d120a-384a-4fcd-9462-d704524b97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "model_size_kb = os.path.getsize(\"bert_model.pth\") / 1024\n",
    "print(f\"Model size: {model_size_kb:.0f} KB\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "# Count trainable parameters\n",
    "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parameter count: {param_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fc6a6-62de-46ba-b81c-fb71f20c3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "mcc = matthews_corrcoef(true_labels, predictions)\n",
    "print(f\"MCC: {mcc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb725b-e213-4930-996e-17448337fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify_text(text):\n",
    "#     \"\"\"Classifies a given text using the trained model.\n",
    "\n",
    "#     Args:\n",
    "#         text (str): The text to classify.\n",
    "\n",
    "#     Returns:\n",
    "#         str: The predicted class label.\n",
    "#     \"\"\"\n",
    "#     # Tokenize the input text\n",
    "#     inputs = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "#     # Move inputs to the device (GPU if available, otherwise CPU)\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#     # Get model predictions\n",
    "#     with torch.no_grad():  # Disable gradient calculation during inference\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     # Get the predicted class label\n",
    "#     predicted_class_id = torch.argmax(outputs.logits).item()\n",
    "#     predicted_class_label = id_to_class[predicted_class_id]\n",
    "\n",
    "#     return predicted_class_label\n",
    "\n",
    "# # Hardcoded input text\n",
    "# custom_text = \"i hate to do this\"  # Replace with your desired text\n",
    "\n",
    "# # Classify the text\n",
    "# predicted_label = classify_text(custom_text)\n",
    "\n",
    "# print(f\"Predicted Label for '{custom_text}': {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
